# deploy_kubernetes
Entendendo de deployando Kubernetes


**Kubernetes (K8S)**

 Antes de iniciarmos, resumo - O que √© Kubernetes?

Desenvolvida pela Google em 2014 e mantido pela CNCF (Cloud Native Computing Foundation), Kubernetes (tamb√©m chamado de K8s) √© uma plataforma de c√≥digo aberto criado com objetivo de ser um orquestrador de containers, automatizando a implanta√ß√£o, o escalonamento e a gest√£o de aplica√ß√µes em containers.

***Nome Curioso, o apelido k8s veio do padr√£o i18n (a letra "K" seguida por oito letras e o "s" no final)***


### **Arquitetura Kubernetes**

Um Cluster K8s segue o modelo construido por control plane / workers, onde o control plane √© o c√©rebro do cluster e o trabalho bruto √© executado dentro dos Workers.

![Arquitetura Kubernetes](imagens/arquitetura.svg)

**Control-plane:** Controle do Cluster!

O Control Plane √© o c√©rebro do cluster Kubernetes. Ele gerencia o estado desejado do cluster, ou seja, define o que deve estar rodando, onde, como e quando.

Dentro do **control-plane** possu√≠mos outros componentes:

**etcd:** Banco de dados chave-valor que armazena todo estado do cluster.

**API-server:** Trabalhando com JSON sobre HTTP, ele √© a porta de entrada para gerenciar o Kubernetes. Para facilitar o gerenciamento, podemos integrar ao utilit√°rio kubectl para facilitar a administra√ß√£o via requisi√ß√µes REST.

**Scheduler:** Respons√°vel pelo n√≥ onde ir√° armazenar os Pods com base na quantidade de recursos dispon√≠veis em cada n√≥.

**Controller-manager:** Executa tarefas que s√£o usadas para monitorar e executar o estado do Pod. Se um pod foi definido com 10 r√©plicas, o controller-manager ir√° ler o √∫ltimo estado setado no etcd e o atual estado do Pod, se divergentes, ele ir√° tentar concilar o pod com o estado estabelecido no etcd.

 

**Workers:** Trabalho bruto!

Os worker nodes s√£o os servidores que rodam os containers da aplica√ß√£o (ou seja, os pods).

**Kubelet:** Agent que conversa diretamente com o controll-manager e √© executado em todos n√≥s dos Workers com a fun√ß√£o de garantir que os containers estejam rodando conforme ao control-plane.

**Kube-proxy:** Trabalhando como um roteador dos Pods, tem a fun√ß√£o de rotear os pacotes de rede dos n√≥s e pods usando IPtables ou IPVS.



arquitetura
````
[Control Plane]
‚îú‚îÄ kube-apiserver       ‚Üê Interface de controle
‚îú‚îÄ etcd                 ‚Üê Armazena estado
‚îú‚îÄ kube-scheduler       ‚Üê Decide onde rodar os pods
‚îî‚îÄ kube-controller-mgr  ‚Üê Garante o estado desejado

[Worker Nodes]
‚îú‚îÄ kubelet              ‚Üê Executor de pods
‚îú‚îÄ kube-proxy           ‚Üê Roteamento de rede
‚îî‚îÄ Container Runtime    ‚Üê Executa containers
````

**Exemplo:** Falamos para o k8s que precisamos de mais inst√¢ncias do Prometheus. O Control-plane ir√° dizer "Quero 4 inst√¢ncias" e os Works ir√£o executar a tarefa.

FLUXO
````
kubectl apply -f app.yaml ‚îÄ‚îÄ‚îÄ‚ñ∂ kube-apiserver ‚îÄ‚îÄ‚îÄ‚ñ∂ etcd (salva estado)
                                  ‚îÇ
                                  ‚ñº
                        kube-scheduler decide node
                                  ‚îÇ
                                  ‚ñº
                   kubelet no node executa pod com o container runtime
                                  ‚îÇ
                                  ‚ñº
                       kube-proxy gerencia o tr√°fego para os pods
````



### Gerenciamento dos Containers (Pod - Menor unidade do Kubernetes)

**Pod:**
Para lidar com os containers, o K8s trabalha com uma abstra√ß√£o chamada de Pod. K8s n√£o acessa o container diretamente, ele organiza dentro de um grupo denominados **Pods**, onde um Pod pode ter v√°rios containers dividindo recursos de mem√≥rias, CPU, volumes, endere√ßos...


**Deployment:** Um dos principais controllers do K8s, ele gerencia o ciclo de vida do Pod por completo, garantindo que um Pod tenha o n√∫mero de r√©plicas determinadas dentro dos workers do cluster. Ele tamb√©m cuida de outras caracteristicas do Pod, como Portas, imagem, atualiza√ß√µes, Volumes e vari√°veis de ambiente, outra caracteristica √© que ele tamb√©m ajuda se integra ao ReplicaSet para garantir alta disponibilidade.


**ReplicaSets:** Respons√°vel por garantir a quantidade de Pods em execu√ß√£o dentro do **n√≥**.

**Services:** Fun√ß√£o de expor os Pods na rede permitindo uma comunica√ß√£o da rede Externa para dentro da Lan do Cluster.

### **Tipos de Services:**

    ClusterIP: Padr√£o ao ser deployado no cluster, tem a fun√ß√£o de expor servi√ßos somente dentro do pr√≥prio cluster, fazendo uma comunica√ß√£o interna entre os servi√ßos.

    exemplo:

    spec:
        type: ClusterIP
        ports:
          - port: 80
           targetPort: 8080


-

    NodePort: Geralmente usada entre as portas 30000 - 32767, tem a fun√ß√£o de expor o pod para a rede Externa.

    exemplo:

    spec:
      type: NodePort
      ports:
        - port: 80
          targetPort: 8080
          nodePort: 30080



-

    LoadBalander: Usado para expor aplica√ß√µes diretamente na Wan como um balanceador de carga. 

    exemplo:

    spec:
      type: LoadBalancer
      ports:
        - port: 80
          targetPort: 8080




**Portas K8s**
````
| Componente           | Porta     | Protocolo | Descri√ß√£o                  |
| -------------------- | --------- | --------- | -------------------------- |
| `kube-apiserver`     | 6443      | HTTPS     | Principal API do cluster   |
| `etcd`               | 2379‚Äì2380 | HTTPS     | Armazena estado do cluster |
| `kube-scheduler`     | 10259     | HTTPS     | Comunica√ß√£o interna        |
| `controller-manager` | 10257     | HTTPS     | Gerencia controladores     |
| `kubelet`            | 10250     | HTTPS     | Comunica√ß√£o com o n√≥       |
| `kube-proxy`         | 10256     | HTTP      | Gerencia regras de rede    |
````

------------


# DEPLOY CLUSTER KUBERNETES

Agora que j√° foi explicado os principais componentes do K8s. Irei criar meu cluster K8s localmente usando o KinD.

[KinD](https://github.com/kubernetes-sigs/kind) (Kubernetes IN Docker) √© uma ferramenta que permite rodar clusters Kubernetes inteiros dentro de containers Docker, de forma r√°pida, leve e local. Ele criado principalmente para desenvolvimento, testes e CI/CD, permitindo simular um ambiente Kubernetes sem precisar de VMs, cloud, ou uma instala√ß√£o pesada. Outra forma de efetuar deploy do K8s localmente √© com o [Minikube](https://minikube.sigs.k8s.io/docs/start/?arch=%2Fwindows%2Fx86-64%2Fstable%2F.exe+download).

Irei instalar o KinD seguindo os requisitos da documenta√ß√£o, como ele usa containers Docker para criar os clusters, irei instalar o Docker.

Instalando Docker:
````
sudo dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo
sudo dnf install docker-ce docker-ce-cli containerd.io
sudo systemctl enable --now docker
````

Permiss√£o ao usu√°rio para usar o Docker
````
sudo usermod -aG docker $USER
newgrp docker
````

![Docker](https://img.icons8.com/?size=100&id=22813&format=png&color=000000)

Docker Instalado!

![Docker](imagens/dockerversion.png)



Deploy KinD
````
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.22.0/kind-linux-amd64
chmod +x kind
sudo mv kind /usr/local/bin/
````

Rode ***kind version*** para verificar a instala√ß√£o.

![Docker](imagens/kindversion.png)


KinD instalado com sucesso!

Para facilitar o gerenciamento do K8s, irei utilizar o utilit√°rio ***kubectl***.

Instalando kubectl:
````
curl -LO https://dl.k8s.io/release/v1.33.0/bin/linux/amd64/kubectl
chmod +x kubectl
sudo mv kubectl /usr/local/bin/
````
````
kubectl version --client
````

![kubectl](imagens/kubectlversion.png)


Depend√™ncias instaladas com sucesso! Agora irei iniciar o processo de cria√ß√£o do Cluster.

````
kind create cluster --name meu-cluster
````
Cluster Criado.

![kind](imagens/kind.png)

Verificando o Cluster:
````
kind get clusters
````

![docker](imagens/clusters.png)


Como o KinD utiliza Docker, com o comando **Docker ps** podemos visualizar o container criado.

![docker](imagens/dockerps.png)

Verificando informa√ß√µes do Cluster:
````
kubectl cluster-info
````
O Control Plane est√° rodando localmente (Kind usa localhost com uma porta aleat√≥ria).O DNS interno (CoreDNS) est√° ativo ‚Äî essencial para comunica√ß√£o entre pods.

![kind](imagens/info.png)


Verificando Nodes(N√≥s):
````
kubectl get node
````
Um √∫nico node (control-plane), com a vers√£o v1.29.2. Est√° com status Ready, ou seja: funcional e aceitando workloads.
![kind](imagens/node.png)

Verificando todos os Pods:
````
kubectl get pods -A
````
Aqui posso ver todos os Pods em Status "Running" no meu cluster.
![kind](imagens/pods.png)

````
Pod	Fun√ß√£o
coredns-xxxx	Resolve nomes DNS dentro do cluster
etcd-meu-cluster-control-plane	Banco de dados do cluster
kube-apiserver-meu-cluster...	API do cluster
kube-controller-manager-...	Controla estados de recursos
kube-scheduler-...	Decide onde rodar pods
kube-proxy	Roteamento de rede
kindnet	Plugin de rede (CNI) usado pelo Kind
local-path-provisioner	Provisionador de volumes persistentes localmente
````

**Cluster Rodando!**

Agora irei instalar uma aplica√ß√£o do nginx como teste de deployment com o comando ***kubectl create nome_do_pod --imagem=***.

Deployment nginx
````
kubectl create deployment nginx --image=nginx
````
Ao utilizar ***kubectl create*** o container nginx √© baixado diretamente do Docker Hub, que √© o reposit√≥rio p√∫blico padr√£o de imagens Docker. Ao passar parametro "--image=nginx" a imagem ser√° buscada em "*docker.io/library/nginx:latest*".

O Kubectl envia o comando para criar o Deployment para o KubeAPI dentro do Control-plane, o control-plane envia a solicita√ß√£o para o Kubelet receber dentro do Worker. Ap√≥s a requisi√ß√£o ser recebida, o container runtime ir√° come√ßar a baixar a imagem direto do Docker Hub.


Ao criar um novo deployment, o status do container fica como "ContainerCreating".
![deployment](imagens/deployment.png)

Ap√≥s esperar alguns segundos, o status muda para "Running".
![deployment](imagens/deployment2.png)

Criando Servi√ßo na porta 80 como NodePort.
````
kubectl expose deployment nginx --port=80 --type=NodePort
kubectl get svc
````
![service](imagens/service.png)


Aplica√ß√£o Deployada e Service criados com sucesso!

Agora irei deletar os pods criados.

**Deletando deployment:** kubectl delete deployment nginx  

**Deletando service:** kubectl delete service nginx  


Posso verificar se ainda existe algum deployment ou service do nginx com **kubectl get ALL**

Podemos notar que todos pods nginx foram exclu√≠dos.
![service](imagens/delete.png)

**Deletando CLUSTER KIND**

````
kind delete cluster --name meu-cluster
````
![delete](imagens/deletes.png)

Cluster KinD Exclu√≠do!

-----------
### Criando Cluster personalizados via manifest YAML

Outra forma de trabalhar com o Kind √© atrav√©s de manifest .yaml onde podemos definindo parametros de porta, redes, quantidades de nodes e Workers.

Irei criar um novo arquivo .yaml definindo as configura√ß√µes do Cluster.

````
nano kind-config.yaml
````
kind-config.yaml
````
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
networking:
  apiServerAddress: "192.168.2.63"  # IP do host f√≠sico
  apiServerPort: 17443
  podSubnet: "10.244.0.0/16"
  serviceSubnet: "10.96.0.0/12"

nodes:
  - role: control-plane
    extraPortMappings:
      - containerPort: 80
        hostPort: 80
      - containerPort: 443
        hostPort: 443
      - containerPort: 6443
        hostPort: 17445
      - containerPort: 30080
        hostPort: 30080    # üî• necess√°rio para acessar NodePort 30080

  - role: worker
````

Deploy

Irei realizar o deploy com o comando kind create cluster --name nome_do_cluster --config meu_manifest.yaml
````
kind create cluster --name meu-cluster --config kind-config.yaml
````

**Cluster deployado via manifest, os Pods est√£o sendo criados.**

![Kind](imagens/kind2.png)



----------------------

### NAMESPACE

Como j√° sabemos, Docker ou outros tipos de containers s√£o isolamentos de recursos, onde o Linux mente para a aplica√ß√£o fazendo ela executar como se estivesse em outra m√°quina com seus pr√≥prios recursos de soft e hardware.

As Namespace s√£o as respons√°veis por este papel, elas s√£o uma divis√£o l√≥gica do Linux onde permite isolar recursos, dentro do Cluster podemos usar namespaces para ter v√°rios ambientes, pods, services, deployments...

Podemos verificar todas as namespaces do cluster:
````
kubectl get namespaces
````
Ao efetuar deploy do KinD, ele j√° cria todas as namespaces necess√°rios para o cluster automaticamente.
![namespace](imagens/namespace.png)

Para verificar os Pods de uma namespace: **kubectl get pods -n nome_da_namespace

Verificando pods da namespace kube-system:
````
kubectl get pod -n kube-system
````

![namespace](imagens/kubesystem.png)


Para verificar todos pods de todas namespaces:
````
kubectl get pods -A
````

-----------------------------------

### Deploy Nginx no Cluster via manifest YAML

````
nano nginx_kubernetes.yaml
````

Manifest nginx_kubernetes.yaml
````
# Namespace
apiVersion: v1
kind: Namespace
metadata:
  name: nginx

---
# Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  namespace: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx:latest
          ports:
            - containerPort: 80

---
# Service
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
  namespace: nginx
spec:
  selector:
    app: nginx
  type: NodePort
  ports:
    - port: 80
      targetPort: 80
      nodePort: 30080  # Porta acess√≠vel no host
````
**Realizando o deployment:** kubectl apply -f nome_do_manifest.yaml
````
kubectl apply -f nginx_kubernetes.yaml
````
![namespace](imagens/deploynginx.png)

Com o comando **kubectl get all -n nginx** eu posso visualizar todos os pods da namespace nginx.

````
kubectl get all -n nginx
````

**Deployment** e **Services** nginx criados com sucesso.
![namespace](imagens/allnginx.png)


Testando Pods Nginx:

Com os Pods em Running, o Service est√° apontando para a porta 30080 e o Type est√° como NodePort, ou seja, o Pod do Nginx est√° sendo exposto para rede.
````
curl https://127.0.0.1:30080
````
![namespace](imagens/curl.png)

**LEMBRE-SE** - No manifest para deploy do cluster *kind-config.yaml* eu passei o parametro para expor a porta:

````
- containerPort: 30080
        hostPort: 30080  
````
Acesso Web Nginx:

![namespace](imagens/nginx.png)




----------
